# mfcc_acoustic_extraction_pipeline

This is an implementation of the Mel-Frequency Cepstral Coefficient (MFCC) acoustic feature extraction pipeline.

## File Descriptions:

1. signal.wav : A speech recording to test the pipeline.
2. mel_filters.npy : A set of pre-computed Mel filter banks.

## MFCC Pipeline Implementation Steps:

1. Load an audio waveform.
2. DC subtraction (i.e. remove the mean of the signal)
3. Pre-emphasis filtering
4. Transforming the audio into a sequence of frames 5. For each frame:

(a) Multiplying the frame with a window function (b) Computing the Fourier transform

(c) Computing the magnitude spectrum from the Fourier transform (d) Computing the power spectrum from the magnitude spectrum (e) Binning the power spectrum with Mel filterbanks

(f) Taking the logarithm of the Mel-filterbank power spectrum

(g) Computing Discrete Cosine Transform (DCT) of the log-Mel-power spectrum (h) Truncating the DCT to keep only the first ğ¶ elements

For an input audio waveform that occupies ğ¹ frames, the resulting MFCC representation of the audio will be a ğ¹ by ğ¶ matrix.

## Loading the File

Using scipy.io.wavfile.read(), we load the signal.wav file from disk. 

## Mean Subtraction

Let ğ‘¥1[ğ‘›] be the raw samples of the audio file. The first step is to perform mean subtraction:

ğ‘¥2[ğ‘›] = ğ‘¥1[ğ‘›] âˆ’ ğ‘¥0

where ğ‘¥0 is the average value of all the samples in the waveform.

## Pre-emphasis

The periodic excitation from the glottis in voiced speech is not an ideal delta train, but is â€œsmoothed.â€ To be more concrete, the harmonics of the excitation fall off in magnitude as a function of frequency at a rate of 1/ğ‘“ 2. The radiation characteristics at the lips partially counteract this by a factor of ğ‘“ , but in order to flatten the spectrum completely we need to apply another filter whose magnitude response is proportional to ğ‘“ . This is achieved with a first order finite impulse response (FIR) filter:

ğ‘¥3[ğ‘›] = ğ‘¥2[ğ‘›] âˆ’ ğ‘ğ‘¥2[ğ‘› âˆ’ 1] 

where ğ‘ = 0.97 is conventionally used.

## Computing Frames

Thenextstepistocomputeaseriesofğ‘ğ‘“ frames,whereeachframe captures a small, fixed-length piece of the signal. The two parameters that control the nature of the frames we will extract are the frame ğ‘™ğ‘’ğ‘›ğ‘”ğ‘¡h (sometimes also called the width) and frame ğ‘ hğ‘–ğ‘“ ğ‘¡ (sometimes also called the â€œhopâ€). Assuming a window length ğ¿ and shift ğ‘† (both specified in samples), The ğ‘˜ğ‘¡h frame will be:

ğ‘¥ğ‘˜[ğ‘›] = ğ‘¥3[ğ‘˜ğ‘† +ğ‘›],ğ‘› = 0,1,2,...,ğ¿âˆ’1

Unless (ğ‘™ğ‘’ğ‘›ğ‘”ğ‘¡h(ğ‘¥3) âˆ’ ğ¿) is exactly divisible by ğ‘†, the very last frame wonâ€™t have enough samples to fill an entire window length ğ¿. In this case, we can just pad the final window with zeros up to length ğ¿.

## Applying the Window Function

The next step is to element-wise multiply each frame ğ‘¥ğ‘˜ [ğ‘›] with a window function ğ‘¤[ğ‘›]:

ğ‘¤ ğ‘¥ğ‘˜ [ğ‘›]=ğ‘¥ğ‘˜[ğ‘›]â‹…ğ‘¤[ğ‘›]

The Hamming window is most commonly used in ASR, and can be created simply by making an appropriate call to the scipy.signal.hamming() function (scipy.signal also has factory functions for a large number of other window types).

## Computing the Fourier Transform

Next, we will compute the Fourier transform of each windowed frame. The â€œdirectâ€ implementation of the DFT is:

ğ‘ ğ‘‹[ğ‘š] = âˆ‘ğ‘¥[ğ‘›]ğ‘’ ğ‘›=0 ğ‘š âˆ’2ğœ‹ğ‘— ğ‘› ğ‘
